{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8677c341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461ade6",
   "metadata": {},
   "source": [
    "Data From \n",
    "Station: 000106 ON I-70 NE/O SH 9, BLUE RIVER PKWY, AT EISENHOWER TUNNEL\t\n",
    "Annual csv files from 2018 to 2023\n",
    "https://dtdapps.coloradodot.info/otis/TrafficData#ui/1/1/0/station/000106/criteria/070A/0/449.589/false/true/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261107dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages needed \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")\n",
    "import kaleido \n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb1a31b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E_2018.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read csvs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Eisenhower_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;28mmap\u001b[39m(pd\u001b[38;5;241m.\u001b[39mread_csv, \n\u001b[0;32m      3\u001b[0m                             [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_2018.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_2019.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_2020.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_2021.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_2023.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert date to a formatted date\u001b[39;00m\n\u001b[0;32m      6\u001b[0m Eisenhower_raw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOUNTDATE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(Eisenhower_raw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormattedDate\u001b[39m\u001b[38;5;124m'\u001b[39m], infer_datetime_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:422\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    420\u001b[0m     objs \u001b[38;5;241m=\u001b[39m [objs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys]\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E_2018.csv'"
     ]
    }
   ],
   "source": [
    "# Read csvs\n",
    "Eisenhower_raw = pd.concat(map(pd.read_csv, \n",
    "                            ['E_2018.csv','E_2019.csv','E_2020.csv', 'E_2021.csv','E_2022.csv','E_2023.csv']))\n",
    "\n",
    "# Convert date to a formatted date\n",
    "Eisenhower_raw['COUNTDATE'] = pd.to_datetime(Eisenhower_raw['FormattedDate'], infer_datetime_format = True)\n",
    "\n",
    "# Set index to formatted date\n",
    "Eisenhower_raw = Eisenhower_raw.set_index('COUNTDATE')\n",
    "\n",
    "# Add weekdays and months using the formatted date \n",
    "Eisenhower_raw['Weekday'] =  Eisenhower_raw.index.dayofweek\n",
    "Eisenhower_raw['Month'] = Eisenhower_raw.index.month\n",
    "\n",
    "# Split dataframe into eastbound and westbound dataframes \n",
    "Eisenhower_West = Eisenhower_raw.loc[Eisenhower_raw.COUNTDIR != 'P', :]  \n",
    "Eisenhower_East = Eisenhower_raw.loc[Eisenhower_raw.COUNTDIR == 'P', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eisenhower_West.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframes into pre and post covid data frames \n",
    "Pre_Eisenhower_West = Eisenhower_West.loc['2019-02-01':'2019-04-30']\n",
    "Pre_Eisenhower_East = Eisenhower_East.loc['2019-02-01':'2019-04-30']\n",
    "\n",
    "Post_Eisenhower_West = Eisenhower_West.loc['2023-02-01':'2023-04-30']\n",
    "Post_Eisenhower_East = Eisenhower_East.loc['2023-02-01':'2023-04-30']\n",
    "\n",
    "During_Eisenhower_West = Eisenhower_West.loc['2020-02-01':'2020-04-30']\n",
    "During_Eisenhower_East = Eisenhower_East.loc['2020-02-01':'2020-04-30']\n",
    "\n",
    "# group them my means of the month and weekday so they have the same number of rows \n",
    "a = Pre_Eisenhower_West.groupby(['Month','Weekday']).mean()\n",
    "b = Post_Eisenhower_West.groupby(['Month','Weekday']).mean()\n",
    "c = During_Eisenhower_West.groupby(['Month','Weekday']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0598173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {1 : 'January', 2 : 'February', 3 : 'March', 4: 'April', 5 : 'May', 6 : 'June', 7 : \n",
    "        'July', 8 : 'August', 9 : 'September', 10 : 'October', 11 : 'November', 12 : 'December'}\n",
    "dict2 = {0 : 'Monday', 1 : 'Tuesday', 2 : 'Wednesday',  3: 'Thursday', 4 : 'Friday', 5 : 'Saturday', 6 : 'Sunday'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd767a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lists for weekdays, months, and hours \n",
    "days_ = list(range(7))\n",
    "days_ = days_ * 72\n",
    "\n",
    "hours_ = list(range(24))\n",
    "hours_ = hours_ * 21\n",
    "hours_.sort()\n",
    "\n",
    "month_ = (list(range(2,3))* 7) + (list(range(3,4))* 7)  + (list(range(4,5))* 7)\n",
    "month_ = month_ * 24\n",
    "\n",
    "# make lists of counts of just one column for all months, weekdays, and hours \n",
    "listPre = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    list1 = list(a.iloc[:,i])\n",
    "    listPre += list1\n",
    "\n",
    "listDur = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    list2 = list(c.iloc[:,i])\n",
    "    listDur += list2\n",
    "    \n",
    "listPost = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    list3 = list(b.iloc[:,i])\n",
    "    listPost += list3\n",
    "    \n",
    "# create dataframes for each covid dataframe with columns month, weekday, hour, and counts \n",
    "dataPre = {'Month' : month_ , 'Weekday': days_ , 'Hour': hours_ , 'CountPre': listPre}\n",
    "PreCovid = pd.DataFrame(dataPre)\n",
    "\n",
    "dataDur = {'Month' : month_ , 'Weekday': days_ , 'Hour': hours_ , 'CountDur': listDur}\n",
    "DurCovid = pd.DataFrame(dataDur)\n",
    "\n",
    "dataPost = {'Month' : month_ , 'Weekday': days_ , 'Hour': hours_ , 'CountPost': listPost}\n",
    "PostCovid = pd.DataFrame(dataPost)\n",
    "PostCovid\n",
    "\n",
    "#merge pre, during, and post covid into one dataframe \n",
    "All_Covid = pd.merge(PreCovid, DurCovid, on = ('Month', 'Weekday', 'Hour'))\n",
    "All_Covid = pd.merge(All_Covid, PostCovid, on = ('Month', 'Weekday', 'Hour'))\n",
    "\n",
    "All_Covid = All_Covid.replace({\"Month\": dict})\n",
    "All_Covid = All_Covid.replace({\"Weekday\": dict2})\n",
    "\n",
    "# make another version of the covid data so that it can all be stacked on top of itself \n",
    "dataPre2 = {'Month' : month_ , 'Weekday': days_ , 'Hour': hours_ , 'Time' : 'Pre', 'Count': listPre}\n",
    "PreCovid2 = pd.DataFrame(dataPre2)\n",
    "\n",
    "dataDur2 = {'Month' : month_ , 'Weekday': days_ , 'Hour': hours_ , 'Time' : 'During', 'Count': listDur}\n",
    "DurCovid2 = pd.DataFrame(dataDur2)\n",
    "\n",
    "dataPost2 = {'Month' : month_ , 'Weekday': days_ , 'Hour': hours_ , 'Time' : 'Post', 'Count': listPost}\n",
    "PostCovid2 = pd.DataFrame(dataPost2)\n",
    "\n",
    "Covid_stacked = pd.concat([PreCovid2, DurCovid2, PostCovid2], axis = 0)\n",
    "\n",
    "Covid_stacked = Covid_stacked.replace({\"Month\": dict})\n",
    "Covid_stacked = Covid_stacked.replace({\"Weekday\": dict2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb937202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframes into west and east during ski season and grouped by weekday \n",
    "W_ski = Eisenhower_West.loc[(Eisenhower_West.Month ==1) | (Eisenhower_West.Month == 2) | \n",
    "                           (Eisenhower_West.Month ==12) | (Eisenhower_West.Month ==3)]\n",
    "\n",
    "W_ski_Weekday = W_ski.groupby('Weekday').mean()\n",
    "\n",
    "E_ski = Eisenhower_East.loc[(Eisenhower_East.Month ==1) | (Eisenhower_East.Month == 2) | \n",
    "                           (Eisenhower_East.Month ==12) | (Eisenhower_East.Month ==3)]\n",
    "\n",
    "E_ski_Weekday = E_ski.groupby('Weekday').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3386eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframes into west and east during summer and grouped by weekday \n",
    "W_summer = Eisenhower_West.loc[(Eisenhower_West.Month ==6) | (Eisenhower_West.Month == 7) | \n",
    "                           (Eisenhower_West.Month ==8) | (Eisenhower_West.Month ==9)]\n",
    "\n",
    "W_summer_Weekday = W_summer.groupby('Weekday').mean()\n",
    "\n",
    "E_summer = Eisenhower_East.loc[(Eisenhower_East.Month ==6) | (Eisenhower_East.Month == 7) | \n",
    "                           (Eisenhower_East.Month ==8) | (Eisenhower_East.Month ==9)]\n",
    "\n",
    "E_summer_Weekday = E_summer.groupby('Weekday').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fdb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframes into west and east during shoulder season and grouped by weekday \n",
    "W_shoulder = Eisenhower_West.loc[(Eisenhower_West.Month == 4) | (Eisenhower_West.Month == 5) | \n",
    "                           (Eisenhower_West.Month ==10) | (Eisenhower_West.Month ==11)]\n",
    "\n",
    "W_shoulder_Weekday = W_shoulder.groupby('Weekday').mean()\n",
    "\n",
    "E_shoulder = Eisenhower_East.loc[(Eisenhower_East.Month ==4) | (Eisenhower_East.Month == 5) | \n",
    "                           (Eisenhower_East.Month ==10) | (Eisenhower_East.Month ==11)]\n",
    "\n",
    "E_shoulder_Weekday = E_shoulder.groupby('Weekday').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of weekdays 0 to 7 that repeats 24 times (0, 1, 2, 3, 4, 5, 6, 0, 1, ...)\n",
    "days = list(range(7))\n",
    "days = days * 24\n",
    "len(days)\n",
    "\n",
    "# Make a list of hours 0 to 23 that repeats 7 times and is sorted (0, 0, 0, 0, 0, 0, 0, 1, 1, ...)\n",
    "hours = list(range(24))\n",
    "hours = hours * 7\n",
    "hours.sort()\n",
    "hours\n",
    "\n",
    "# pull each hour column and stack them to make a list of traffic counts \n",
    "# for ski season (winter)\n",
    "listWW = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    lista = list(W_ski_Weekday.iloc[:,i])\n",
    "    listWW += lista\n",
    "listWW\n",
    "\n",
    "listWE = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    listb = list(E_ski_Weekday.iloc[:,i])\n",
    "    listWE += listb\n",
    "listWE\n",
    "\n",
    "# for summmer\n",
    "listSW = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    listc = list(W_summer_Weekday.iloc[:,i])\n",
    "    listSW += listc\n",
    "listSW\n",
    "\n",
    "listSE = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    listd = list(E_summer_Weekday.iloc[:,i])\n",
    "    listSE += listd\n",
    "listSE\n",
    "\n",
    "# for shoulder season (spring/fall)\n",
    "listShW = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    liste = list(W_shoulder_Weekday.iloc[:,i])\n",
    "    listShW += liste\n",
    "len(listShW)\n",
    "\n",
    "listShE = []\n",
    "column = range(1,25)\n",
    "for i in column:\n",
    "    listf = list(E_shoulder_Weekday.iloc[:,i])\n",
    "    listShE += listf\n",
    "\n",
    "\n",
    "# create dataframes using the days, hours, and list of counts \n",
    "# winter\n",
    "dataWW = {'Weekday': days, 'Hour': hours, 'Count': listWW}\n",
    "W_ski_weekday = pd.DataFrame(dataWW)\n",
    "W_ski_weekday = W_ski_weekday.replace({\"Weekday\": dict2})\n",
    "\n",
    "dataWE = {'Weekday': days, 'Hour': hours, 'Count': listWE}\n",
    "E_ski_weekday= pd.DataFrame(dataWE)\n",
    "E_ski_weekday = E_ski_weekday.replace({\"Weekday\": dict2})\n",
    "\n",
    "# summer\n",
    "dataSW = {'Weekday': days, 'Hour': hours, 'Count': listSW}\n",
    "W_summer_weekday = pd.DataFrame(dataSW)\n",
    "W_summer_weekday = W_summer_weekday.replace({\"Weekday\": dict2})\n",
    "\n",
    "dataSE = {'Weekday': days, 'Hour': hours, 'Count': listSE}\n",
    "E_summer_weekday= pd.DataFrame(dataSE)\n",
    "E_summer_weekday = E_summer_weekday.replace({\"Weekday\": dict2})\n",
    "\n",
    "# spring/fall\n",
    "dataShW = {'Weekday': days, 'Hour': hours, 'Count': listShW}\n",
    "W_shoulder_weekday = pd.DataFrame(dataShW)\n",
    "W_shoulder_weekday = W_shoulder_weekday.replace({\"Weekday\": dict2})\n",
    "\n",
    "dataShE = {'Weekday': days, 'Hour': hours, 'Count': listShE}\n",
    "E_shoulder_weekday= pd.DataFrame(dataShE)\n",
    "E_shoulder_weekday = E_shoulder_weekday.replace({\"Weekday\": dict2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fcb00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#E_W_Ski = pd.merge(EastSki, WestSki, on = ('Hour','Weekday'))\n",
    "#E_W_Summer = pd.merge(EastSummer, WestSummer, on = ('Hour','Weekday'))\n",
    "#E_W_Shoulder = pd.merge(EastShoulder, WestShoulder, on = ('Hour','Weekday'))\n",
    "#E_W_Ski.loc[E_W_Ski.Weekday == 4, ].plot.bar(x = 'Hour', y = ['Count_ESki' , 'Count_WSki'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6ec73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename count column in each data frame\n",
    "EastSki = E_ski_weekday.rename(columns={\"Count\": \"Count_ESki\"})\n",
    "WestSki = W_ski_weekday.rename(columns={\"Count\": \"Count_WSki\"})\n",
    "WestSummer = W_summer_weekday.rename(columns={\"Count\": \"Count_WSummer\"})\n",
    "EastSummer = E_summer_weekday.rename(columns={\"Count\": \"Count_ESummer\"})\n",
    "WestShoulder = W_shoulder_weekday.rename(columns={\"Count\": \"Count_WShoulder\"})\n",
    "EastShoulder = E_shoulder_weekday.rename(columns={\"Count\": \"Count_EShoulder\"})\n",
    "\n",
    "# merge data frame into one dataframe that includes counts for each season east and west \n",
    "All_Seasons = pd.merge(EastSki, WestSki, on = ('Hour','Weekday'))\n",
    "All_Seasons = pd.merge(All_Seasons, EastSummer, on = ('Hour','Weekday'))\n",
    "All_Seasons = pd.merge(All_Seasons, WestSummer, on = ('Hour','Weekday'))\n",
    "All_Seasons = pd.merge(All_Seasons, EastShoulder, on = ('Hour','Weekday'))\n",
    "All_Seasons = pd.merge(All_Seasons, WestShoulder, on = ('Hour','Weekday'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11618223",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe that show all points East and West for time 0, 6, 10, 16, 20\n",
    "list0_ = list(Eisenhower_West['HOUR0'])\n",
    "list6_ = list(Eisenhower_West['HOUR6'])\n",
    "list10_ = list(Eisenhower_West['HOUR10'])\n",
    "list16_ = list(Eisenhower_West['HOUR16'])\n",
    "list20_ = list(Eisenhower_West['HOUR20'])\n",
    "listdate = list(Eisenhower_West['FormattedDate'])\n",
    "listweekday = list(Eisenhower_West['Weekday'])\n",
    "listdate_ = listdate * 5\n",
    "hours_ = list0_ + list6_ + list10_ + list16_ + list20_\n",
    "list0_E = list(Eisenhower_East['HOUR0'])\n",
    "list6_E = list(Eisenhower_East['HOUR6'])\n",
    "list10_E = list(Eisenhower_East['HOUR10'])\n",
    "list16_E = list(Eisenhower_East['HOUR16'])\n",
    "list20_E = list(Eisenhower_East['HOUR20'])\n",
    "hours_E = list0_E + list6_E + list10_E + list16_E + list20_E\n",
    "weekday = listweekday * 5\n",
    "time_ = [0, 6, 10, 16, 20]\n",
    "time = time_ * 2037\n",
    "time.sort()\n",
    "timeseries = {'Date' : listdate_, 'Time' : time, 'Count_W' : hours_ , 'Count_E' : hours_E , 'Weekday' : weekday}\n",
    "Timeseries = pd.DataFrame(timeseries)\n",
    "Timeseries['COUNTDATE'] = pd.to_datetime(Timeseries['Date'], infer_datetime_format = True)\n",
    "Timeseries = Timeseries.sort_values(['COUNTDATE', 'Time'])\n",
    "Timeseries = Timeseries.set_index('COUNTDATE')\n",
    "Timeseries['Month'] = Timeseries.index.month\n",
    "Timeseries['Year'] = Timeseries.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bfe866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe that consist of the mean hourly count of cars for each month of each year \n",
    "Group_Time = Timeseries.groupby(['Year', 'Month']).agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0238fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remname all months and days to appropriate names \n",
    "dict = {1 : 'January', 2 : 'February', 3 : 'March', 4: 'April', 5 : 'May', 6 : 'June', 7 : \n",
    "        'July', 8 : 'August', 9 : 'September', 10 : 'October', 11 : 'November', 12 : 'December'}\n",
    "dict2 = {0 : 'Monday', 1 : 'Tuesday', 2 : 'Wednesday',  3: 'Thursday', 4 : 'Friday', 5 : 'Saturday', 6 : 'Sunday'}\n",
    "Timeseries = Timeseries.replace({\"Month\": dict})\n",
    "Timeseries = Timeseries.replace({\"Weekday\": dict2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdb1c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#& ((All_Seasons.Hour > 4) & (All_Seasons.Hour < 20))\n",
    "All_Seasons.loc[(All_Seasons.Weekday == 'Friday'), ].plot.bar(\n",
    "    x = 'Hour', y = ['Count_WSki', 'Count_WSummer', 'Count_WShoulder'], \n",
    "    label = ['Ski Season \\n (Dec/Jan/Feb/Mar)', 'Summer \\n (June/July/Aug/Sept)', 'Shoulder Season \\n (April/May/Oct/Nov)'],  \n",
    "    color = ['blue','pink', 'brown'], \n",
    "    figsize = (12, 4), \n",
    "    width = .75, \n",
    "    edgecolor='white')\n",
    "plt.title('Mean Traffic Volume Counts by Season - Friday Westbound', fontsize = 12)\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.ylabel('Traffic Count (per hour)')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbe020",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#All_Seasons.loc[(All_Seasons.Weekday == 'Sunday') & (All_Seasons.Hour < 12), ].plot.bar(\n",
    "All_Seasons.loc[(All_Seasons.Weekday == 'Sunday'), ].plot.bar(\n",
    "    x = 'Hour', y = ['Count_WSki', 'Count_WSummer', 'Count_WShoulder'], \n",
    "    label = ['Ski Season \\n (Dec/Jan/Feb/Mar)', 'Summer \\n (June/July/Aug/Sept)', 'Shoulder Season \\n (April/May/Oct/Nov)'],  \n",
    "    color = ['blue','pink', 'brown'], \n",
    "    figsize = (12, 4), \n",
    "    width = .75, \n",
    "    edgecolor='white')\n",
    "plt.title('Mean Traffic Volume Counts by Season - Saturday Westbound', fontsize = 12)\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.ylabel('Traffic Count (per hour)')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Seasons.loc[(All_Seasons.Weekday == 'Friday') & (All_Seasons.Hour > 12), ].plot.bar(\n",
    "     x = 'Hour', y = ['Count_WSki', 'Count_WSummer', 'Count_WShoulder'], \n",
    "    label = ['Ski Season \\n (Dec/Jan/Feb/Mar)', 'Summer \\n (June/July/Aug/Sept)', 'Shoulder Season \\n (April/May/Oct/Nov)'],  \n",
    "    color = ['blue','pink', 'brown'], \n",
    "    figsize = (12, 4), \n",
    "    width = .75, \n",
    "    edgecolor='white')\n",
    "plt.title('Mean Traffic Volume Counts by Season - Friday', fontsize = 12)\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.ylabel('Total Count (per hour)')\n",
    "plt.xlabel('24 hour clock (hours)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not nearly as much Sunday am traffic during shoulder season (April, May, October, November)\n",
    "All_Seasons.loc[(All_Seasons.Weekday == 'Sunday'), ].plot.bar(\n",
    "      x = 'Hour', y = ['Count_ESki', 'Count_ESummer', 'Count_EShoulder'], \n",
    "    label = ['Ski Season \\n (Dec/Jan/Feb/Mar)', 'Summer \\n (June/July/Aug/Sept)', 'Shoulder Season \\n (April/May/Oct/Nov)'],  \n",
    "    color = ['blue','pink', 'brown'], \n",
    "    figsize = (12, 4), \n",
    "    width = .75, \n",
    "    edgecolor='white')\n",
    "plt.title('Mean Traffic Volume Counts by Season - Sunday Eastbound', fontsize = 12)\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.ylabel('Total Count (per hour)')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Seasons.loc[(All_Seasons.Weekday == 'Saturday'), ].plot.bar(\n",
    "     x = 'Hour', y = ['Count_ESki', 'Count_ESummer', 'Count_EShoulder'], \n",
    "    label = ['Ski Season \\n (Dec/Jan/Feb/Mar)', 'Summer \\n (June/July/Aug/Sept)', 'Shoulder Season \\n (April/May/Oct/Nov)'],  \n",
    "    color = ['blue','pink', 'brown'], \n",
    "    figsize = (12, 4), \n",
    "    width = .75, \n",
    "    edgecolor='white')\n",
    "plt.title('Mean Traffic Volume Counts by Season - Saturday Eastbound', fontsize = 12)\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.ylabel('Total Count (per hour)')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d6921",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Westbound_Winter= px.scatter(W_ski_weekday, x=\"Hour\", y=\"Count\", color=\"Weekday\",\n",
    "           hover_name=\"Weekday\", title = 'Westbound Hourly Mean Traffic Count by Weekday During Ski Season')\n",
    "\n",
    "Westbound_Winter.update_yaxes(title = 'Traffic Count')\n",
    "Westbound_Winter.update_xaxes(title = 'Time')\n",
    "\n",
    "Westbound_Winter.show()\n",
    "Westbound_Winter.write_image(\"images/Westbound_Winter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710fccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Westbound_Summer= px.scatter(W_summer_weekday, x=\"Hour\", y=\"Count\", color=\"Weekday\",\n",
    "           hover_name=\"Weekday\", title = 'Westbound Hourly Mean Traffic Count by Weekday During the Summer')\n",
    "\n",
    "Westbound_Summer.update_yaxes(title = 'Traffic Count')\n",
    "Westbound_Summer.update_xaxes(title = 'Time')\n",
    "Westbound_Summer.write_image(\"images/Westbound_Summer.png\")\n",
    "Westbound_Summer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf91837",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Westbound_Shoulder= px.scatter(W_shoulder_weekday, x=\"Hour\", y=\"Count\", color=\"Weekday\",\n",
    "           hover_name=\"Weekday\", range_y = (0,2000), title = 'Westbound Hourly Mean Traffic Count by Weekday During Shoulder Season')\n",
    "Westbound_Shoulder.update_yaxes(title = 'Traffic Count')\n",
    "Westbound_Shoulder.update_xaxes(title = 'Time')\n",
    "Westbound_Shoulder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6722f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Eastbound_Winter = px.scatter(E_ski_weekday, x=\"Hour\", y=\"Count\", color=\"Weekday\",\n",
    "           hover_name=\"Weekday\", title = 'Eastbound Hourly Mean Traffic Count by Weekday During Ski Season')\n",
    "\n",
    "\n",
    "Eastbound_Winter.update_yaxes(title = 'Traffic Count')\n",
    "Eastbound_Winter.update_xaxes(title = 'Time')\n",
    "Eastbound_Winter.show()\n",
    "#Eastbound_Winter.write_image(\"images/Eastbound_Winter_byWeekday.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31618166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think high traffic Sunday am due to travel to airport??? Many 5 - 8 pm flights \n",
    "Eastbound_Summer= px.scatter(E_summer_weekday, x=\"Hour\", y=\"Count\", color=\"Weekday\",\n",
    "           hover_name=\"Weekday\", title = 'Eastbound Hourly Mean Traffic Count by Weekday During the Summer')\n",
    "\n",
    "Eastbound_Summer.update_yaxes(title = 'Traffic Count')\n",
    "Eastbound_Summer.update_xaxes(title = 'Time')\n",
    "Eastbound_Summer.show()\n",
    "#Eastbound_Winter.write_image(\"images/Eastbound_Winter_byWeekday.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eastbound_Shoulder= px.scatter(E_shoulder_weekday, x=\"Hour\", y=\"Count\", color=\"Weekday\",\n",
    "           hover_name=\"Weekday\", title = 'Eastbound Hourly Mean Traffic Count by Weekday During the Shoulder Season')\n",
    "\n",
    "Eastbound_Shoulder.update_yaxes(title = 'Traffic Count')\n",
    "Eastbound_Shoulder.update_xaxes(title = 'Time')\n",
    "Eastbound_Shoulder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25368a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not significant dif. pre and post covid westbound in Feb to April \n",
    "scipy.stats.f_oneway(All_Covid.CountPre, All_Covid.CountPost, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686973ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# very significant difference during covid \n",
    "scipy.stats.f_oneway(All_Covid.CountPre, All_Covid.CountDur, All_Covid.CountPost, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(All_Covid.CountDur, All_Covid.CountPre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_stacked.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a89f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.violin(Covid_stacked, y = 'Count', x= \"Time\", \n",
    "                box=True, \n",
    "                points=\"suspectedoutliers\",  \n",
    "                width = 1000, \n",
    "                title = 'Distribution of Mean Hourly Traffic grouped by Month and Weeekday')\n",
    "fig.update_traces(fillcolor = 'green',\n",
    "                  line_color = 'blue',\n",
    "                  marker_line_outliercolor= 'black',\n",
    "                  box_fillcolor = 'red',\n",
    "                  opacity = 0.5)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['Pre', 'During', 'Post'],\n",
    "    y=[706.4, 354.75, 724.5],\n",
    "    mode=\"markers+text\",\n",
    "    name=\"Markers and Text\",\n",
    "    text=[\"Median = \\n 706.4\", \"Median = \\n 354.75\", \"Median = \\n 724.5\"],\n",
    "    textposition=\"bottom right\"\n",
    "))\n",
    "\n",
    "fig.update_yaxes(title = 'Mean Traffic Count (per hour)')\n",
    "fig.update_xaxes(title = 'Time Period Relative to Covid-19 Pandemic')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e64232",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Covid_Correlation = px.scatter_matrix(All_Covid, dimensions=['CountPre', 'CountDur', 'CountPost'], \n",
    "                                      color=\"Month\", \n",
    "                                      color_discrete_sequence = ['blue', 'cyan', 'purple'], \n",
    "                                      title = 'Relationship among Pre, During, and Post-Pandemic Mean Hourly Traffic Counts')\n",
    "Covid_Correlation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ef239",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.bar(Covid_stacked, x= \"Hour\", y= \"Count\", color= \"Month\", \n",
    "             barmode=\"relative\", facet_row=\"Time\", facet_col=\"Weekday\", \n",
    "             labels ={\"Weekday\": \"Day\"},\n",
    "             color_discrete_sequence = ['blue', 'cyan', 'purple'],\n",
    "             title = 'Weekly and Monthly Variation in Traffic Pre, During, and Post-Pandemic ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee40abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EW_weekdays = Eisenhower_West.replace ({'Weekday': dict2})\n",
    "EE_weekdays = Eisenhower_East.replace ({'Weekday': dict2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b27ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.violin(EW_weekdays, y = 'HOUR6', x= \"Weekday\", \n",
    "                box=True, \n",
    "                points=\"suspectedoutliers\", \n",
    "                hover_data= Eisenhower_West.columns, \n",
    "                width = 1000, \n",
    "                title = 'Distribution of all Westbound Traffic at 6 am')\n",
    "fig.update_traces(fillcolor = 'green',\n",
    "                  line_color = 'blue',\n",
    "                  marker_line_outliercolor= 'black',\n",
    "                  box_fillcolor = 'red',\n",
    "                  opacity = 0.5)\n",
    "fig.update_yaxes(title = 'Traffic Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7bf6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.violin(EE_weekdays, y = 'HOUR10', x= \"Weekday\", \n",
    "                box=True, \n",
    "                points=\"suspectedoutliers\", \n",
    "                hover_data= Eisenhower_West.columns, \n",
    "                width = 1000, \n",
    "                title = 'Distribution of all Eastbound Traffic at 10 am')\n",
    "fig.update_traces(fillcolor = 'green',\n",
    "                  line_color = 'blue',\n",
    "                  marker_line_outliercolor= 'black',\n",
    "                  box_fillcolor = 'red',\n",
    "                  opacity = 0.5)\n",
    "fig.update_yaxes(title = 'Traffic Count')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9a67e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# possibly want to use median instead of mean because of so many outlyers\n",
    "# don't really get outlyers (especially high outlyers) at peak traffic \n",
    "Box2 = Eisenhower_West[['Weekday', 'HOUR7']]\n",
    "Box2.boxplot(by = 'Weekday', column = 'HOUR7')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedf78c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Box2 = Eisenhower_West[['Weekday', 'HOUR16']]\n",
    "Box2.boxplot(by = 'Weekday', column = 'HOUR16')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d2aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Box = Eisenhower_East[['Weekday', 'HOUR10']]\n",
    "Box.boxplot(by = 'Weekday', column = 'HOUR10')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adc9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Box = Eisenhower_East[['Weekday', 'HOUR17']]\n",
    "Box.boxplot(by = 'Weekday', column = 'HOUR17')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46a402",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Group_Time.iloc[:, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Group_Time.iloc[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69788d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure().set_figwidth(12)\n",
    "a = range(0,69)\n",
    "plt.plot(a,'Count_E', data = Group_Time, color = 'purple', label = 'Traffic Count')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Traffic Count (per hour)')\n",
    "plt.xticks(range(0,70,6))\n",
    "plt.title('Monthly Variation in Mean Hourly Traffic Count - Eisenhower Tunnel I-70E CO')\n",
    "plt.grid(True, linestyle='-')\n",
    "plt.vlines([0, 12, 24, 36, 48, 60], 0, 1000, linestyles='--', colors='blue', label = 'January')\n",
    "plt.vlines([6, 18, 30, 42, 54, 66], 0, 1000, linestyles='--', colors='pink', label = 'July')\n",
    "plt.vlines(26.48, 0, 1000, linestyles='--', colors='orange', label = '3/15/2020 \\n Vail Resorts close')\n",
    "plt.vlines(24.58, 0, 1000, linestyles='--', colors='red', label = '1/18/2020 \\n 1st US Covid case')\n",
    "plt.legend(frameon = True, framealpha = 1, facecolor = 'w', bbox_to_anchor = (.8, .5), loc = 'upper left')\n",
    "plt.xticks(ticks=[0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66], \n",
    "           labels=['1/2018', '7/2018', '1/2019', '7/2019','1/2020', '7/2020','1/2021', '7/2021',\n",
    "                   '1/2022', '7/2022','1/2023', '7/2023'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025c737",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure().set_figwidth(12)\n",
    "a = range(0,69)\n",
    "plt.plot(a,'Count_W', data = Group_Time, color = 'olive', label = 'Traffic Count')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Traffic Count (per hour)')\n",
    "plt.xticks(range(0,70,6))\n",
    "plt.title('Monthly Variation in Mean Hourly Traffic Count - Eisenhower Tunnel I-70W CO')\n",
    "plt.grid(True, linestyle='-')\n",
    "plt.vlines([0, 12, 24, 36, 48, 60], 0, 1000, linestyles='--', colors='blue', label = 'January')\n",
    "plt.vlines([6, 18, 30, 42, 54, 66], 0, 1000, linestyles='--', colors='pink', label = 'July')\n",
    "plt.vlines(26.48, 0, 1000, linestyles='--', colors='orange', label = '3/15/2020 \\n Vail Resorts close')\n",
    "plt.vlines(24.58, 0, 1000, linestyles='--', colors='red', label = '1/18/2020 \\n 1st US Covid case')\n",
    "plt.legend(frameon = True, framealpha = 1, facecolor = 'w', bbox_to_anchor = (.8, .5), loc = 'upper left')\n",
    "plt.xticks(ticks=[0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66], \n",
    "           labels=['1/2018', '7/2018', '1/2019', '7/2019','1/2020', '7/2020','1/2021', '7/2021',\n",
    "                   '1/2022', '7/2022','1/2023', '7/2023'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe8a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = go.Figure()\n",
    "\n",
    "\n",
    "fig3.add_trace(go.Scatter(x=Timeseries.index, y=Timeseries.Count_E,\n",
    "                    mode='lines',\n",
    "                    name='East',\n",
    "                    line_color = 'purple'))\n",
    "fig3.add_trace(go.Scatter(x=Timeseries.index, y=Timeseries.Count_W,\n",
    "                    mode='lines',\n",
    "                    name='West',\n",
    "                    line_color = 'olive'))\n",
    "\n",
    "fig3.update_layout(width = 1400, height = 600, title = 'Traffic Volume Counts at the Eisenhower Tunnel I-70 CO')\n",
    "fig3.update_yaxes(title = 'Traffic Count (per hour)')\n",
    "fig3.update_xaxes(title = 'Date')\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0caf0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Timeseries.groupby('Time')['Count_W', 'Count_E'].mean().plot.bar(\n",
    "    color = ['olive', 'purple'],\n",
    "    figsize = (10, 4),\n",
    "    width = .5,\n",
    "    edgecolor = 'white')\n",
    "plt.title('Hourly Mean Traffic Volume', fontsize = 12)\n",
    "#plt.legend()\n",
    "plt.ylabel('Traffic Count')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026473b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figday = px.bar(Timeseries.groupby('Weekday')['Count_W', 'Count_E'].mean(), \n",
    "       barmode = 'group',  \n",
    "       title = 'Mean Hourly Traffic Volume by Day of the Week (mean from 12am, 6am, 10am, 4pm, and 8pm)',\n",
    "       color_discrete_sequence = ['olive', 'purple'],\n",
    "       category_orders = {'Weekday' : ['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "                                      'Friday', 'Saturday', 'Sunday']})\n",
    "\n",
    "figday.update_yaxes(title = 'Traffic Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad844fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Timeseries.groupby('Month')['Count_W', 'Count_E'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1f96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figmonth = px.bar(Timeseries.groupby('Month')['Count_W', 'Count_E'].mean(), \n",
    "       barmode = 'group',  \n",
    "       title = 'Mean Hourly Traffic Volume by Month (mean from 12am, 6am, 10am, 4pm, and 8pm)',\n",
    "       color_discrete_sequence = ['olive', 'purple'],\n",
    "       category_orders = {'Month' : ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                                   'July', 'August', 'September', 'October', 'November', 'December']})\n",
    "\n",
    "figmonth.add_trace(go.Scatter(\n",
    "    x=['April', 'July', 'October'],\n",
    "    y=[700, 950, 750],\n",
    "    mode=\"text\",\n",
    "    name=\"Markers and Text\",\n",
    "    text=[\"Shoulder Season\", \"Summer\", \"Shoulder Season\"],\n",
    "    textposition=\"bottom right\"\n",
    "))\n",
    "\n",
    "figmonth.add_trace(go.Scatter(\n",
    "    x=['February', 'December'],\n",
    "    y=[900, 800],\n",
    "    mode=\"text\",\n",
    "    name=\"Markers and Text\",\n",
    "    text=[\"Ski Season\", 'Ski Season'],\n",
    "    textposition=\"bottom center\"\n",
    "))\n",
    "\n",
    "figmonth.update_yaxes(title = 'Traffic Count')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
